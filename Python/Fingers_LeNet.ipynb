{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "# --------------\n",
    "import cv2\n",
    "import os\n",
    "import errno\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage import io, transform \n",
    "# from IPython.display import display, Image\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Directory\r\n",
    "# -------------\r\n",
    "BASE_DIR = 'D:/MDP/Skripsi/Program/Fingers-Dataset/Pre-Processing/'\r\n",
    "\r\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, (os.listdir(BASE_DIR)[1]+'/'))\r\n",
    "VAL_DIR = os.path.join(BASE_DIR, (os.listdir(BASE_DIR)[2]+'/'))\r\n",
    "\r\n",
    "\r\n",
    "# Check Image Shape Data Training\r\n",
    "# -------------------------------\r\n",
    "kelas = os.listdir(TRAIN_DIR)[4]   # Data Kelas ke-\r\n",
    "fpath = os.path.join(TRAIN_DIR, (kelas+'/'))  \r\n",
    "fname = os.listdir(fpath)[0]        # File Name \r\n",
    "fdir = fpath+fname                  # File Directory\r\n",
    "\r\n",
    "shape_old = cv2.imread(fdir).shape      # Shape (tuple)\r\n",
    "x = list(shape_old)     \r\n",
    "\r\n",
    "x[0] = x[1] = 32                        # Reshape (32,32,3) atau Resize\r\n",
    "input_shape = tuple(x)                  # Input Shape\r\n",
    "\r\n",
    "print('File Directory :', fdir)\r\n",
    "print('File Name      :', fname)\r\n",
    "print('Image Shape    :', shape_old, '==> Original')\r\n",
    "print('Image Reshape  :', input_shape, '==> LeNet', '\\n')\r\n",
    "\r\n",
    "target_size = x = list(input_shape)\r\n",
    "target_size.remove(3)\r\n",
    "target_size = tuple(target_size)        # Target Size\r\n",
    "print('Target Size    :', target_size)\r\n",
    "print('Kelas          :', kelas)\r\n",
    "\r\n",
    "io.imshow(transform.resize(io.imread(fdir), (x[0], x[1])))\r\n",
    "io.show()\r\n",
    "# display(Image(filename=fdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Arsitektur LeNet CNN\r\n",
    "# ---------------------------\r\n",
    "model = Sequential()\r\n",
    "\r\n",
    "# Layer Feature Learning\r\n",
    "# ----------------------\r\n",
    "model.add(Conv2D(6, kernel_size=5, strides=1, activation='relu', input_shape=input_shape))\r\n",
    "# model.add(AveragePooling2D(pool_size=2, strides=2))\r\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\r\n",
    "\r\n",
    "model.add(Conv2D(16, kernel_size=5, strides=1, activation='relu'))\r\n",
    "# model.add(AveragePooling2D(pool_size=2, strides=2))\r\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\r\n",
    "\r\n",
    "model.add(Conv2D(120, kernel_size=5, strides=1, activation='relu')) \r\n",
    "\r\n",
    "# Layer Classification\r\n",
    "# --------------------\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(84, activation='relu'))\r\n",
    "model.add(Dense(12, activation='softmax')) # Output Class\r\n",
    "\r\n",
    "# Compile Optimizer\r\n",
    "# --------------------\r\n",
    "# SGD, RMSprop, Adam\r\n",
    "model.compile(loss='categorical_crossentropy',\r\n",
    "              optimizer=Adam(lr=0.00001),\r\n",
    "              metrics=['acc'])\r\n",
    "\r\n",
    "# Print Model LeNet\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentasi Data Training & Validation\r\n",
    "# -------------------------------------\r\n",
    "# target_size = target_size\r\n",
    "\r\n",
    "batch_size_train = 300\r\n",
    "batch_size_val = 120\r\n",
    "\r\n",
    "Train_DataGen = ImageDataGenerator().flow_from_directory(\r\n",
    "    TRAIN_DIR,\r\n",
    "    target_size=target_size,\r\n",
    "    batch_size=batch_size_train,\r\n",
    "    class_mode='categorical'\r\n",
    ")\r\n",
    "\r\n",
    "Val_DataGen = ImageDataGenerator().flow_from_directory(\r\n",
    "    VAL_DIR,\r\n",
    "    target_size=target_size,\r\n",
    "    batch_size=batch_size_val,\r\n",
    "    class_mode='categorical'\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\r\n",
    "# -----------\r\n",
    "\r\n",
    "# AveragePooling, MaxPooling\r\n",
    "# SGD, RMSprop, Adam\r\n",
    "\r\n",
    "pooling_layer = 'MaxPooling'\r\n",
    "optimizer = 'Adam'\r\n",
    "#-------------------------------\r\n",
    "model_dir = 'D:/MDP/Skripsi/Program/Python/LeNet/Model/'+pooling_layer+'/'+optimizer+'/'\r\n",
    "\r\n",
    "model_name = 'LeNet-'+pooling_layer+'-'+optimizer\r\n",
    "file_path = model_dir+model_name+'-{epoch:02d}-{acc:.4f}-{val_acc:.4f}.h5'\r\n",
    "\r\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
    "    filepath=file_path,\r\n",
    "    save_weights_only=False,\r\n",
    "    monitor='val_acc',\r\n",
    "    mode='max',\r\n",
    "    save_best_only=True\r\n",
    ")\r\n",
    "s = time.time()\r\n",
    "model_history = model.fit(\r\n",
    "    Train_DataGen,\r\n",
    "    steps_per_epoch=54,    # 16.200 images = batch_size * steps_per_epoch  => Train\r\n",
    "    epochs=25,\r\n",
    "    validation_data=Val_DataGen,\r\n",
    "    validation_steps=27,    # 3.240 images = batch_size * steps_per_epoch   => Validation\r\n",
    "    callbacks=[model_checkpoint_callback]\r\n",
    ")\r\n",
    "print('\\n\\nTotal time :', round(time.time() - s, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation\r\n",
    "# ----------------------------\r\n",
    "\r\n",
    "plot_path = 'D:/MDP/Skripsi/Program/Python/LeNet/Plot/'\r\n",
    "\r\n",
    "# model_name = 'LeNet-MaxPooling-RMSprop'\r\n",
    "\r\n",
    "try:\r\n",
    "    os.mkdir(plot_path)\r\n",
    "except OSError as exc:\r\n",
    "    if exc.errno == errno.EEXIST and os.path.isdir(plot_path):\r\n",
    "        pass\r\n",
    "    else:\r\n",
    "        raise\r\n",
    "\r\n",
    "plot_name = model_name\r\n",
    "plot_dir = plot_path+plot_name+'-Plot.png'\r\n",
    "\r\n",
    "acc = model_history.history['acc']\r\n",
    "val_acc = model_history.history['val_acc']\r\n",
    "loss = model_history.history['loss']\r\n",
    "val_loss = model_history.history['val_loss']\r\n",
    "\r\n",
    "# Get Number Epoch\r\n",
    "epochs = range(len(acc))\r\n",
    "\r\n",
    "plt.figure(figsize=(12,6))\r\n",
    "# Plot Training & Validation Acc Per Epoch\r\n",
    "plt.subplot(1,2,1)\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.plot(epochs,acc,'r',label='training')\r\n",
    "plt.plot(epochs,val_acc,'b',label='validation')\r\n",
    "plt.legend()\r\n",
    "plt.title('Accuracy')\r\n",
    "\r\n",
    "# Plot Training & Validation Loss Per Epoch\r\n",
    "plt.subplot(1,2,2)\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.plot(epochs,loss,'r',label='training')\r\n",
    "plt.plot(epochs,val_loss,'b',label='validation')\r\n",
    "plt.legend()\r\n",
    "plt.title('Loss')\r\n",
    "\r\n",
    "plt.suptitle(plot_name)\r\n",
    "plt.tight_layout()\r\n",
    "plt.savefig(plot_dir, facecolor='w')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\r\n",
    "# ----------\r\n",
    "\r\n",
    "# AveragePooling, MaxPooling\r\n",
    "# SGD, RMSprop, Adam\r\n",
    "\r\n",
    "pooling_layer = 'MaxPooling'\r\n",
    "optimizer = 'Adam'\r\n",
    "#-------------------------------\r\n",
    "model_dir = 'D:/MDP/Skripsi/Program/Python/LeNet/Model/'+pooling_layer+'/'+optimizer+'/'\r\n",
    "\r\n",
    "file_name = os.listdir(model_dir)[-1]  # index terakhir\r\n",
    "\r\n",
    "model = load_model(os.path.join(model_dir, file_name))\r\n",
    "model.summary()\r\n",
    "\r\n",
    "\r\n",
    "# Set Folder Path And Label\r\n",
    "# -------------------------\r\n",
    "\r\n",
    "# Label True Classes\r\n",
    "finger_list = ['0L','0R','1L','1R','2L','2R','3L','3R','4L','4R','5L','5R']\r\n",
    "list_acc = []   \r\n",
    "lbl_predict = []        # Label Predict\r\n",
    "target_size = (32,32)\r\n",
    "# batch_size = 20\r\n",
    "data_class = 12         # Total Data Class \r\n",
    "data_per_label = 180    # Total Data Per Label ['0L','0R','1L','1R','2L','2R','3L','3R','4L','4R','5L','5R']\r\n",
    "data_test = 2160        # Total Data Test\r\n",
    "\r\n",
    "# Label Actual\r\n",
    "lbl_actual = []\r\n",
    "for i in range(data_class):\r\n",
    "    for j in range(data_per_label):\r\n",
    "        lbl_actual.append(i)\r\n",
    "print(lbl_actual)\r\n",
    "\r\n",
    "# Label Finger Path\r\n",
    "path = 'D:/MDP/Skripsi/Program/Fingers-Dataset/Pre-Processing/Testing/'  \r\n",
    "\r\n",
    "fingers_path = []\r\n",
    "\r\n",
    "for i in range(len(finger_list)):\r\n",
    "    fingers_path.append(path+finger_list[i]+'/')\r\n",
    "print(fingers_path)\r\n",
    "\r\n",
    "\r\n",
    "# Predict Data\r\n",
    "# ------------------------\r\n",
    "for i in range(len(fingers_path)):\r\n",
    "    fingers_img = []\r\n",
    "    for j in os.listdir(fingers_path[i]):\r\n",
    "\r\n",
    "        j = os.path.join(fingers_path[i], j)\r\n",
    "        j = image.load_img(j, target_size=target_size)\r\n",
    "        j = image.img_to_array(j)\r\n",
    "        j = np.expand_dims(j, axis=0)\r\n",
    "        fingers_img.append(j)\r\n",
    "\r\n",
    "    # Set Stack up fingers_img for Prediction\r\n",
    "    fingers_img = np.vstack(fingers_img)\r\n",
    "    # prediction_classes = model.predict_classes(fingers_img, batch_size=batch_size)\r\n",
    "    prediction_classes = np.argmax(model.predict(fingers_img), axis=-1)\r\n",
    "    lbl_predict.extend(prediction_classes)\r\n",
    "\r\n",
    "    # Print Result\r\n",
    "    print('\\n\\n----------------------------------------------------------------------------')\r\n",
    "    print('Label Name [', finger_list[i], '] == ', i, \r\n",
    "        '\\nPrediction_Class = \\n\\n', prediction_classes, \r\n",
    "        '\\nTotal True Prediction = ', list(prediction_classes).count(i),\r\n",
    "        '\\nTotal Data Test       = ', data_per_label,\r\n",
    "        '\\nAccuracy per Label    = ', round(int(list(prediction_classes).count(i)) / data_per_label * 100, 2),'%',\r\n",
    "        '\\n----------------------------------------------------------------------------\\n')\r\n",
    "    list_acc.append(list(prediction_classes).count(i))\r\n",
    "\r\n",
    "\r\n",
    "print('Result Test Accuracy = ', round((sum(list_acc) / data_test) * 100, 2),'%','\\n\\n')\r\n",
    "\r\n",
    "\r\n",
    "# Confusion Matrix\r\n",
    "# ----------------\r\n",
    "actual = lbl_actual\r\n",
    "predicted = lbl_predict\r\n",
    "\r\n",
    "print('---------------- Confusion Matrix ----------------\\n\\n','X = Predict\\n Y = Actual\\n\\n', confusion_matrix(actual, predicted), '\\n\\n')\r\n",
    "print(classification_report(actual, predicted, target_names=finger_list, digits=4))\r\n",
    "\r\n",
    "print('\\n------------------- Overall Score -------------------\\n')\r\n",
    "\r\n",
    "precision   = precision_score(actual, predicted, average='weighted') * 100\r\n",
    "recall      = recall_score(actual, predicted, average='weighted') * 100\r\n",
    "f1          = f1_score(actual, predicted, average='weighted') * 100\r\n",
    "accuracy    = accuracy_score(actual, predicted) * 100\r\n",
    "\r\n",
    "print('Precision    :', round(precision, 2), '%\\n----------------------')\r\n",
    "print('Recall       :', round(recall, 2), '%\\n----------------------')\r\n",
    "print('F1-Score     :', round(f1, 2), '%\\n----------------------')\r\n",
    "print('Accuracy     :', round(accuracy, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi 1 Gambar\r\n",
    "\r\n",
    "img = image.load_img(fdir, target_size=target_size)\r\n",
    "implot = plt.imshow(img)\r\n",
    "\r\n",
    "im = image.img_to_array(img)\r\n",
    "im = np.expand_dims(im, axis=0)\r\n",
    "\r\n",
    "imx = np.vstack([im])\r\n",
    "prediction = model.predict_classes(imx, batch_size=1)\r\n",
    "# prediction = np.argmax(model.predict(imx), axis=-1)\r\n",
    "prediction = prediction\r\n",
    "\r\n",
    "print('\\n')\r\n",
    "print('File Name  :', fname)\r\n",
    "print('Prediction Class :', prediction)\r\n",
    "\r\n",
    "if (prediction==0):\r\n",
    "    print('Prediction : 0L')\r\n",
    "elif (prediction==1):\r\n",
    "    print('Prediction : 0R')\r\n",
    "elif (prediction==2):\r\n",
    "    print('Prediction : 1L')    \r\n",
    "elif (prediction==3):\r\n",
    "    print('Prediction : 1R')    \r\n",
    "elif (prediction==4):\r\n",
    "    print('Prediction : 2L')    \r\n",
    "elif (prediction==5):\r\n",
    "    print('Prediction : 2R')\r\n",
    "elif (prediction==6):\r\n",
    "    print('Prediction : 3L')    \r\n",
    "elif (prediction==7):\r\n",
    "    print('Prediction : 3R')    \r\n",
    "elif (prediction==8):\r\n",
    "    print('Prediction : 4L')    \r\n",
    "elif (prediction==9):\r\n",
    "    print('Prediction : 4R')\r\n",
    "elif (prediction==10):\r\n",
    "    print('Prediction : 5L')    \r\n",
    "elif (prediction==11):\r\n",
    "    print('Prediction : 5R')\r\n",
    "else:\r\n",
    "    print('Prediction : Unknown')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "from pandas import ExcelWriter\r\n",
    "\r\n",
    "y_actual = pd.Series(actual, name='Actual')\r\n",
    "y_pred = pd.Series(predicted, name='Predicted')\r\n",
    "\r\n",
    "df_confusion = pd.crosstab(y_actual, y_pred)\r\n",
    "\r\n",
    "print(df_confusion)\r\n",
    "\r\n",
    "# df_confusion.to_csv('test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit",
   "name": "python384jvsc74a57bd059c957619cd247f189cf6c0d4d0788feac2b0a224dd36ec7630f0d0efdf5c9fb"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}