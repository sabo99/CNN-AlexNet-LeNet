{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\r\n",
    "# --------------\r\n",
    "import cv2\r\n",
    "import os\r\n",
    "import errno\r\n",
    "import time\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from skimage import io, transform \r\n",
    "\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "from keras.models import Sequential, load_model\r\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense\r\n",
    "from keras.optimizers import SGD, RMSprop, Adam\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.preprocessing import image\r\n",
    "from keras import metrics\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Directory\r\n",
    "# -------------\r\n",
    "BASE_DIR = 'D:/MDP/Skripsi/Program/Fingers-Dataset/Pre-Processing/'\r\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, (os.listdir(BASE_DIR)[1]+'/'))\r\n",
    "VAL_DIR = os.path.join(BASE_DIR, (os.listdir(BASE_DIR)[2]+'/'))\r\n",
    "\r\n",
    "# Check Image Shape Data Training\r\n",
    "# -------------------------------\r\n",
    "kelas = os.listdir(TRAIN_DIR)[0]    # [0] = 1L   \r\n",
    "fpath = os.path.join(TRAIN_DIR, (kelas+'/'))  \r\n",
    "fname = os.listdir(fpath)[0]        # File Name \r\n",
    "fdir = fpath+fname                  # File Directory\r\n",
    "\r\n",
    "shape_old = cv2.imread(fdir).shape      # Shape (tuple)\r\n",
    "x = list(shape_old)     \r\n",
    "x[0] = x[1] = 227                       # Reshape (227,227,3)\r\n",
    "input_shape = tuple(x)                  # Input Shape\r\n",
    "\r\n",
    "print('File Directory :', fdir)\r\n",
    "print('File Name      :', fname)\r\n",
    "print('Image Shape    :', shape_old, '==> Original')\r\n",
    "print('Image Reshape  :', input_shape, '==> AlexNet', '\\n')\r\n",
    "\r\n",
    "target_size = x = list(input_shape)\r\n",
    "target_size.remove(3)\r\n",
    "target_size = tuple(target_size)        # Target Size\r\n",
    "print('Target Size    :', target_size)\r\n",
    "print('Kelas          :', kelas)\r\n",
    "\r\n",
    "io.imshow(transform.resize(io.imread(fdir), (x[0], x[1])))\r\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Arsitektur AlexNet CNN\n",
    "# -----------------------------\n",
    "model = Sequential()\n",
    "\n",
    "# Layer Feature Learning\n",
    "# ----------------------\n",
    "model.add(Conv2D(16, kernel_size=11, strides=4, activation='relu', input_shape=input_shape))\n",
    "model.add(AveragePooling2D(pool_size=3, strides=2))\n",
    "# model.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=5, strides=1, activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=3, strides=2))\n",
    "# model.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu')) \n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu')) \n",
    "model.add(Conv2D(32, kernel_size=3, strides=1, activation='relu')) \n",
    "model.add(AveragePooling2D(pool_size=3, strides=2))\n",
    "# model.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "\n",
    "# Layer Classification\n",
    "# --------------------\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(12, activation='softmax')) # Output Class\n",
    "\n",
    "\n",
    "# Compile Optimizer\n",
    "# -----------------\n",
    "# SGD, RMSprop, Adam\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.00001), #1.0e-5\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Print Model AlexNet\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentasi Data Training & Validation\n",
    "# -------------------------------------\n",
    "batch_size_train = 300\n",
    "batch_size_val = 120\n",
    "\n",
    "Train_DataGen = ImageDataGenerator().flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size_train,\n",
    "    class_mode='categorical',\n",
    "    # shuffle=True\n",
    ")\n",
    "\n",
    "Val_DataGen = ImageDataGenerator().flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size_val,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "# -----------\n",
    "\n",
    "# AveragePooling, MaxPooling\n",
    "# SGD, RMSprop, Adam\n",
    "\n",
    "pooling_layer = 'AveragePooling'\n",
    "optimizer = 'SGD'\n",
    "#-------------------------------\n",
    "model_dir = 'D:/MDP/Skripsi/Program/Python/AlexNet/Model/'+pooling_layer+'/'+optimizer+'/'\n",
    "model_name = 'AlexNet-'+pooling_layer+'-'+optimizer\n",
    "file_path = model_dir+model_name+'-{epoch:02d}-{acc:.4f}-{val_acc:.4f}.h5'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=file_path,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "s = time.time()\n",
    "model_history = model.fit(\n",
    "    Train_DataGen,\n",
    "    steps_per_epoch=54,    # 16.200 images = batch_size * steps_per_epoch  => Train\n",
    "    epochs=25,\n",
    "    validation_data=Val_DataGen,\n",
    "    validation_steps=27,    # 3.240 images = batch_size * steps_per_epoch   => Validation\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")\n",
    "print('\\n\\nTotal time :', round(time.time() - s, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation\n",
    "# ----------------------------\n",
    "plot_path = 'D:/MDP/Skripsi/Program/Python/AlexNet/Plot/'\n",
    "\n",
    "try:\n",
    "    os.mkdir(plot_path)\n",
    "except OSError as exc:\n",
    "    if exc.errno == errno.EEXIST and os.path.isdir(plot_path):\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "plot_name = model_name\n",
    "plot_dir = plot_path+plot_name+'-Plot.png'\n",
    "\n",
    "acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "# Get Number Epoch\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "# Plot Training & Validation Acc Per Epoch\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs,acc,'r',label='training')\n",
    "plt.plot(epochs,val_acc,'b',label='validation')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "# Plot Training & Validation Loss Per Epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(epochs,loss,'r',label='training')\n",
    "plt.plot(epochs,val_loss,'b',label='validation')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.suptitle(plot_name)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir, facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\r\n",
    "# ----------\r\n",
    "\r\n",
    "# AveragePooling, MaxPooling\r\n",
    "# SGD, RMSprop, Adam\r\n",
    "\r\n",
    "pooling_layer = 'MaxPooling'\r\n",
    "optimizer = 'Adam'\r\n",
    "#-------------------------------\r\n",
    "model_dir = 'D:/MDP/Skripsi/Program/Python/LeNet/Model/'+pooling_layer+'/'+optimizer+'/'\r\n",
    "\r\n",
    "file_name = os.listdir(model_dir)[-1]  # index terakhir\r\n",
    "\r\n",
    "model = load_model(os.path.join(model_dir, file_name))\r\n",
    "model.summary()\r\n",
    "\r\n",
    "\r\n",
    "# Set Folder Path And Label\r\n",
    "# -------------------------\r\n",
    "\r\n",
    "# Label True Classes\r\n",
    "finger_list = ['0L','0R','1L','1R','2L','2R','3L','3R','4L','4R','5L','5R']\r\n",
    "list_acc = []   \r\n",
    "lbl_predict = []        # Label Predict\r\n",
    "target_size = (227,227)\r\n",
    "# batch_size = 20\r\n",
    "data_class = 12         # Total Data Class \r\n",
    "data_per_label = 180    # Total Data Per Label ['0L','0R','1L','1R','2L','2R','3L','3R','4L','4R','5L','5R']\r\n",
    "data_test = 2160        # Total Data Test\r\n",
    "\r\n",
    "# Label Actual\r\n",
    "lbl_actual = []\r\n",
    "for i in range(data_class):\r\n",
    "    for j in range(data_per_label):\r\n",
    "        lbl_actual.append(i)\r\n",
    "# print(lbl_actual)\r\n",
    "\r\n",
    "# Label Finger Path\r\n",
    "path = 'D:/MDP/Skripsi/Program/Fingers-Dataset/Pre-Processing/Testing/'\r\n",
    "\r\n",
    "fingers_path = []\r\n",
    "\r\n",
    "for i in range(len(finger_list)):\r\n",
    "    fingers_path.append(path+finger_list[i])\r\n",
    "# print(fingers_path)\r\n",
    "\r\n",
    "\r\n",
    "# Count Accuracy Per Label\r\n",
    "# ------------------------\r\n",
    "for i in range(len(fingers_path)):\r\n",
    "    fingers_img = []\r\n",
    "    for j in os.listdir(fingers_path[i]):\r\n",
    "\r\n",
    "        j = os.path.join(fingers_path[i], j)\r\n",
    "        j = image.load_img(j, target_size=target_size)\r\n",
    "        j = image.img_to_array(j)\r\n",
    "        j = np.expand_dims(j, axis=0)\r\n",
    "        fingers_img.append(j)\r\n",
    "\r\n",
    "    # Set Stack up fingers_img for Prediction\r\n",
    "    fingers_img = np.vstack(fingers_img)\r\n",
    "    prediction_classes = np.argmax(model.predict(fingers_img), axis=-1)\r\n",
    "    lbl_predict.extend(prediction_classes)\r\n",
    "\r\n",
    "  # Print Result\r\n",
    "    print('\\n\\n----------------------------------------------------------------------------')\r\n",
    "    print('Label Name [', finger_list[i], '] == ', i+1, \r\n",
    "        '\\nPrediction_Class = \\n\\n', prediction_classes+1, \r\n",
    "        '\\nTotal True Prediction = ', list(prediction_classes).count(i),\r\n",
    "        '\\nTotal Data Test       = ', data_per_label,\r\n",
    "        '\\nAccuracy per Label    = ', round(int(list(prediction_classes).count(i)) / data_per_label * 100, 2),'%',\r\n",
    "        '\\n----------------------------------------------------------------------------\\n')\r\n",
    "    list_acc.append(list(prediction_classes).count(i))\r\n",
    "\r\n",
    "print('Result Test Accuracy = ', '%.2f' % round((sum(list_acc)/data_test)*100, 2),'%','\\n\\n')\r\n",
    "\r\n",
    "\r\n",
    "# Confusion Matrix\r\n",
    "# ----------------\r\n",
    "actual = lbl_actual\r\n",
    "predicted = lbl_predict\r\n",
    "\r\n",
    "print('---------------- Confusion Matrix ----------------\\n\\n','X = Predict\\n Y = Actual\\n\\n', confusion_matrix(actual, predicted), '\\n\\n')\r\n",
    "print(classification_report(actual, predicted, target_names=finger_list, digits=4))\r\n",
    "\r\n",
    "print('\\n------------------- Overall Score -------------------\\n')\r\n",
    "precision   = precision_score(actual, predicted, average='weighted') * 100\r\n",
    "recall      = recall_score(actual, predicted, average='weighted') * 100\r\n",
    "accuracy    = accuracy_score(actual, predicted) * 100\r\n",
    "f1          = f1_score(actual, predicted, average='weighted') * 100\r\n",
    "\r\n",
    "print('Precision    :', round(precision, 2), '%\\n----------------------')\r\n",
    "print('Recall       :', round(recall, 2), '%\\n----------------------')\r\n",
    "print('F1-Score     :', round(f1, 2), '%\\n----------------------')\r\n",
    "print('Accuracy     :', round(accuracy, 2), '%')\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi 1 Gambar\n",
    "\n",
    "kelas = os.listdir(TRAIN_DIR)[0]    # [0] = 1L   \n",
    "fpath = os.path.join(TRAIN_DIR, (kelas+'/'))  \n",
    "fname = os.listdir(fpath)[0]        # File Name \n",
    "fdir = fpath+fname                  # File Directory\n",
    "\n",
    "img = image.load_img(fdir, target_size=target_size)\n",
    "implot = plt.imshow(img)\n",
    "\n",
    "im = image.img_to_array(img)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "\n",
    "imx = np.vstack([im])\n",
    "# prediction = model.predict_classes(imx, batch_size=1)\n",
    "prediction = np.argmax(model.predict(imx), axis=-1)\n",
    "prediction = prediction+1\n",
    "\n",
    "print('\\n')\n",
    "print('File Name  :', fname)\n",
    "print('Prediction :', prediction)\n",
    "if (prediction==1):\n",
    "    print('Prediction : 0L')\n",
    "elif (prediction==2):\n",
    "    print('Prediction : 0R')\n",
    "elif (prediction==3):\n",
    "    print('Prediction : 1L')    \n",
    "elif (prediction==4):\n",
    "    print('Prediction : 1R')    \n",
    "elif (prediction==5):\n",
    "    print('Prediction : 2L')    \n",
    "elif (prediction==6):\n",
    "    print('Prediction : 2R')\n",
    "elif (prediction==7):\n",
    "    print('Prediction : 3L')    \n",
    "elif (prediction==8):\n",
    "    print('Prediction : 3R')    \n",
    "elif (prediction==9):\n",
    "    print('Prediction : 4L')    \n",
    "elif (prediction==10):\n",
    "    print('Prediction : 4R')\n",
    "elif (prediction==11):\n",
    "    print('Prediction : 5L')    \n",
    "elif (prediction==12):\n",
    "    print('Prediction : 5R')\n",
    "else:\n",
    "    print('Result : Unknown')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "y_actual = pd.Series(actual, name='Actual')\n",
    "y_pred = pd.Series(predicted, name='Predicted')\n",
    "\n",
    "df_confusion = pd.crosstab(y_actual, y_pred)\n",
    "\n",
    "print(df_confusion)\n",
    "\n",
    "# df_confusion.to_csv('test.csv')\n",
    "# df_confusion.to_excel('test.xlsx')\n",
    "# # wr = ExcelWriter('test.xlsx')\n",
    "# # df_confusion.to_excel(wr, 'Sheet1')\n",
    "# # wr.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accurracies = []\n",
    "for lbl_actual in np.unique(y_actual):\n",
    "    x = np.mean(y_pred[y_actual == lbl_actual] == lbl_actual)\n",
    "    class_acc = round((x * 100),2)\n",
    "    class_accurracies.append(class_acc)\n",
    "    \n",
    "print (class_accurracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit",
   "name": "python384jvsc74a57bd059c957619cd247f189cf6c0d4d0788feac2b0a224dd36ec7630f0d0efdf5c9fb"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}